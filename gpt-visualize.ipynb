{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pymupdf\n",
    "#!pip install --upgrade pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./sample.pdf\"\n",
    "output_dir = \"./output\"\n",
    "output_filename = \"result\"\n",
    "tesseract_path = \"C:/Program Files/Tesseract-OCR/tesseract.exe\" # Default installation path of Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "from pathlib import Path\n",
    "debug_dir = f\"{output_dir}/debug\"\n",
    "Path(debug_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to image\n",
    "PDFs can have incorrect text encoding or contain images withing itself, it is better to \n",
    "convert pdf pages to images and then perform OCR to extract the text.\n",
    "\n",
    "We convert only the first page to an image since we assume that it's the title page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "dpi = 300\n",
    "zoom_factor = dpi / 72\n",
    "\n",
    "# Read first page\n",
    "doc = fitz.open(pdf_path)\n",
    "page = doc[0]\n",
    "\n",
    "# Convert to image\n",
    "mat = fitz.Matrix(zoom_factor, zoom_factor)\n",
    "pix = page.get_pixmap(matrix=mat)\n",
    "image_data = pix.tobytes(\"png\")\n",
    "image = Image.open(BytesIO(image_data))\n",
    "image.save(f\"{debug_dir}/first_page.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare OCR\n",
    "\n",
    "https://github.com/UB-Mannheim/tesseract/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = tesseract_path\n",
    "ocr_result = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_strings(json_obj, strings=[]):\n",
    "    if isinstance(json_obj, dict):\n",
    "        for value in json_obj.values():\n",
    "            get_all_strings(value, strings)\n",
    "    elif isinstance(json_obj, list):\n",
    "        for item in json_obj:\n",
    "            get_all_strings(item, strings)\n",
    "    elif isinstance(json_obj, str):\n",
    "        strings.append(json_obj)\n",
    "    return strings\n",
    "\n",
    "def get_lowest_level_keys(json_doc):\n",
    "    def recurse(obj, keys, parent_key=None):\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    recurse(v, keys, k)\n",
    "                else:\n",
    "                    keys.append(k)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                if isinstance(item, (dict, list)):\n",
    "                    recurse(item, keys, parent_key)\n",
    "                else:\n",
    "                    if parent_key:\n",
    "                        keys.append(parent_key)\n",
    "\n",
    "    keys = []\n",
    "    recurse(json_doc, keys)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import ImageDraw\n",
    "import json\n",
    "\n",
    "with open(\"./gpt_output.json\") as file:\n",
    "    gpt_output_contents = file.read()\n",
    "\n",
    "gpt_json_dict = json.loads(gpt_output_contents)\n",
    "\n",
    "labeled_image = image.copy()\n",
    "draw = ImageDraw.Draw(labeled_image)\n",
    "word_list = [value.split() for value in get_all_strings(gpt_json_dict)]\n",
    "feature_list = get_lowest_level_keys(gpt_json_dict)\n",
    "\n",
    "output_json = {}\n",
    "match_progress_list = [0] * len(word_list)\n",
    "match_start_indices = [-1] * len(word_list)\n",
    "\n",
    "# Magic\n",
    "for i, ocr_word in enumerate(ocr_result[\"text\"]):\n",
    "    if ocr_word.strip():\n",
    "        for j, match_word_arr in enumerate(word_list):\n",
    "            if match_progress_list[j] < len(match_word_arr):\n",
    "                match_word = match_word_arr[match_progress_list[j]]\n",
    "\n",
    "                if match_word.lower() in ocr_word.lower():\n",
    "                    if match_progress_list[j] == 0:\n",
    "                        match_start_indices[j] = i\n",
    "\n",
    "                    match_progress_list[j] += 1\n",
    "\n",
    "                    if match_progress_list[j] == len(match_word_arr):\n",
    "                        start_index = match_start_indices[j]\n",
    "                        end_index = i + 1\n",
    "\n",
    "                        x = ocr_result[\"left\"][start_index]\n",
    "                        y = ocr_result[\"top\"][start_index]\n",
    "                        w = sum(ocr_result[\"width\"][start_index:end_index]) + match_progress_list[j] * zoom_factor * 2\n",
    "                        h = max(ocr_result[\"height\"][start_index:end_index])\n",
    "\n",
    "                        bbox = (x, y, x + w, y + h)\n",
    "                        draw.rectangle(bbox, outline=\"green\", width=2)\n",
    "\n",
    "                        output_json.setdefault(feature_list[j], []).append({\"text\": \" \".join(match_word_arr), \"bounding_box\": bbox})\n",
    "\n",
    "                        match_progress_list[j] = 0\n",
    "                        match_start_indices[j] = -1\n",
    "                else:\n",
    "                    match_progress_list[j] = 0\n",
    "                    match_start_indices[j] = -1\n",
    "\n",
    "output_path = f\"{output_dir}/{output_filename}\"\n",
    "\n",
    "with open(f\"{output_path}.json\", 'w') as json_file:\n",
    "    json.dump(output_json, json_file)\n",
    "\n",
    "labeled_image.save(f\"{output_path}.png\")\n",
    "\n",
    "print(f\"Extracted features JSON saved to: {output_path}.json\")\n",
    "print(f\"Annotated image saved to: {output_path}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
